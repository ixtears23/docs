- 토픽 생성/수정
- 프로듀서(데이터 전송)  
- 컨슈머(데이터수신)

### 1. kafka-topics.sh
**토픽**  
카프카에서 데이터를 구분하는 가장 기본적인 개념  
RDBMS의 테이블과 유사  
카프카 클러스터에 토픽 여러개 존재 가능  
토픽에는 파티션 존재  
파티션은 1개부터 시작  
파티션을 통해 한 번에 처리할 수 있는 데이터양을 늘릴 수 있고  
토픽 내부에서도 파티션을 통해 데이터의 종류를 나누어 처리 가능  

카프카클러스터(1) - (n)토픽(n) - (n)파티션  

**토픽 생성하는 2가지 방법**  
1. 컨슈머 또는 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대해 데이터를 요청할 때
2. 커맨드 라인 툴로 명시적으로 토픽을 생성

토픽마다 데이터의 특성에 따라 옵션을 다르게 설정할 수 있음  

예)  
- 동시데이터 처리량이 많은 경우 : 파티션의 개수를 100으로 설정
- 단기간 데이터 처리만 필요한 경우 : 데이터의 보관기간을 짧게 설정

#### 토픽 생성
~~~shell
$ bin/kafka-topics.sh --create --bootstrap-server test.kafka:9092 --topic hello.kafka
~~~
~~~shell
$ bin/kafka-topics.sh --create --bootstrap-server test.kafka:9092 --partitions 3 --replication-factor 1 --config retention.ms=172800000 --topic hello.kafka.2
~~~
- replication-factor : 최대 개수 설정은 카프카의 브로커 개수, 현재 1개만 사용중이므로 1로 설정, 2로 설정하면 1개의 복제복을 사용하겠다는 의미
- retention.ms : 172800000ms 는 2일, 2일이 지난 토픽의 데이터는 삭제 됨

> 토픽 생성 시 --zookeeper가 아니라 --bootstrap-server 옵션을 사용하는 이유
> 카프카 2.1 이하 버전에서는 카프카 커맨드 툴이 주키퍼와 직접 통신하여 명령 실행
> 카프카 2.2 이후 버전부터 카프카를 통해 토픽과 관련된 명령어를 실행할 수 있게 됨
> 주키퍼와 직접 통신은 아키텍처의 복잡도를 높임

#### 토픽 리스트 조회
~~~shell
$ bin/kafka-topics.sh --bootstrap-server test.kafka:9092 --list
~~~

#### 토픽 상태 확인
~~~shell
$ bin/kafka-topics.sh --bootstrap-server test.kafka:9092 --describe --topic hello.kafka.2
~~~

Leader 가 0으로 표시된 것은 0번 브로커에 파티션이 위치하고 있음을 나타냄  
성능이슈가 발생하면 확인해서, 토픽의 리더 파티션 쏠림 현상을 확인해 볼 수 있음  

#### 토픽 옵션 수정
- kafka-topics.sh : 파티션 개수 변경  
- kafka-configs.sh : 토픽 삭제 정책인 리텐션 기간 변경

**파티션 개수 변경 및 리텐션 기간 변경**
~~~shell
$ bin/kafka-topics.sh --bootstrap-server test.kafka:9092 --topic hello.kafka --alter --partitions 4
$ bin/kafka-topics.sh --bootstrap-server test.kafka:9092 --topic hello.kafka --describe
$ bin/kafka-configs.sh --bootstrap-server test.kafka:9092 --entity-type topics --entity-name hello.kafka --alter --add-config retention.ms=86400000
$ bin/kafka-configs.sh --bootstrap-server test.kafka:9092 --entity-type topics --entity-name hello.kafka --describe
~~~

- 파티션 개수 변경 : --alter옵션과 --partitions옵션을 함께 사용
- 리텐션 기간 변경 : kafka-configs.sh, --alter, --add-config 옵션 사용
  add-config 옵션 : 이미 존재하는 설정값은 변경하고 존재하지 않는 설정값은 신규로 추가


### 2. kafka-console-producer.sh
- 레코드 : 토픽에 넣는 데이터
  - 메세지 키
  - 메세지 값

kafka-console-producer.sh 로 전송되는 레코드 값은 UTF-8을 기반으로  
Byter로 변환되고 ByteArraySerializer로만 직렬화 됨  
즉, String이 아닌 타입으로는 직렬화하여 전송할 수 없음  

다른 타입으로 직렬화하여 데이터를 브로커로 전송하고 싶다면 카프카 프로듀서 애플리케이션을 직접 개발해야 함  

**메시지 키 전송**
~~~shell
$ bin/kafka-console-producer.sh --bootstrap-server test.kafka:9092 --topic hello.kafka
> 1
> 2
> 3
> hello
~~~


**메세지 키/값 전송**
~~~shell
$ bin/kafka-console-producer.sh --bootstrap-server test.kafka:9092 --topic hello.kafka --property "parse.key=true" --property "key.separator=:"
> key1:no1
> key2:no2
> key3:no3
~~~
- parse.key=true  
  레코드를 전송할 때 메시지 키를 추가할 수 있음
- key.separator
  메시지 키와 메시지 값을 구분하는 구분자를 선언
  기본 설정은 Tab delimiter(\t)

> 메시지 키가 null 인 경우
> 프로듀서가 파티션으로 전송할 때 레코드 배치 단위(레코드 전송 묶음)로 라운드 로빈으로 전송
  
> 메시지 키가 존재하는 경우
> 키의 해시값을 작성하여 존재하는 파티션 중 한 개에 할당
> 메시지 키가 동일한 경우에는 동일한 파티션으로 전송

> 파티션 추가 후 파티션과 메시지키의 일관성을 보장 하려면,
> 커스텀 파티셔너를 만들어서 운영해야 함
> 기본 파티셔너는 이전 메시지 키가 0번에 들어갔다고 추가된 파티션에도 0번으로 들어간다는 보장이 없음  

### 3. kafka-console-consumer.sh
~~~shell
$ bin/kafka-console-consumer.sh --bootstrap-server test.kafka:9092 --topic hello.kafka --from-beginning
~~~

**메시지 키 및 메세지 값 확인**
~~~shell
$ bin/kafka-console-consumer.sh --bootstrap-server test.kafka:9092 --topic hello.kafka --property print.key=true --property key.separator="-" --group hello-group --from-beginning
~~~

- print.key=true
  기본 설정값이 false이기 때문에 true 값을 주지 않으면 메세지 키를 확인할 수 없음
- key.separator  
  메세지 키 값을 구분하기 위해 설정
  "-" 로 설정했으므로 <메세지키>-<메세지값> 형태로 출력
- --group  
  신규 컨슈머 그룹 생성
  컨슈머 그룹은 1개 이상의 컨슈머로 구성됨
  컨슈머 그룹을 통해 가져간 토픽의 메세지는 가져간 메세지에 대해 커밋함
  커밋 : 컨슈머가 특정 레코드까지 처리를 완료했다고 레코드의 오프셋 번호를 카프카 브로커에 저장하는 것
  커밋 정보는 __consumer_offsets 이름의 내부 토픽에 저장

> 카프카 프로듀서로 전송했던 데이터의 순서가 컨슈머로 출력한 순서와 다른 이유
> 카프카의 핵심인 파티션 개념 때문
> 토픽의 모든 파티션으로부터 동일한 중요도로 데이터를 가져가기 때문에 순서가 달라짐
> 순서 보장을 원한다면 파티션 1개로 구성된 토픽을 만드는 것
> 한 개의 파티션에는 데이터의 순서를 보장

### 4. kafka-consumer-groups.sh
컨슈머 그룹은 따로 생성하는 명령없이, 컨슈머를 동작할 때 컨슈머 그룹 이름을 지정하면 생성 됨  

**컨슈머 그룹 리스트 확인**
~~~shell
$ bin/kafka-consumer-groups.sh --bootstrap-server test.kafka:9092 --list
~~~

**컨슈머 그룹 상세 확인**
~~~shell
$ bin/kafka-consumer-groups.sh --bootstrap-server test.kafka:9092 --group hello-group --describe
~~~

### 5. kafka-verifiable-producer, consumer.sh
String 타입 메세지 값을 코드 없이 주고 받을 수 있음  
카프카 클러스터 설치가 완료된 이후에 토픽에 데이터를 전송하여 간단한 네트워크 동신 테스트를 할 때 유용함  

~~~shell
$ bin/kafka-verifiable-producer.sh --bootstrap-server test.kafka:9092 --max-messages 10 --topic verify-test
~~~

~~~shell
$ bin/kafka-verifiable-consumer.sh --bootstrap-server test.kafka:9092 --topic verify-test --group-id test-group
~~~

### 6. kafka-delete-records.sh
이미 적재된 토픽의 데이터를 지우는 방법  
가장 오래된 데이터(가장 낮은 숫자의 offset) 부터 특정 시점의 오프셋까지 삭제할 수 있음  

~~~shell
$ vi delete-topic.json

$ bin/kafka-delete-records.sh --bootstrap-server test.kafka:9092 --offset-json-file delete-topic.json
~~~

***delete-topic.json***
~~~json
{
  "partitions": [
    {
      "topic": "test",
      "partition": 0,
      "offset": 50
    }
  ],
  "version": 1
}
~~~

> 카프카에서는 토픽의 파티션에 저장된 특정 데이터만 삭제할 수 없다  
