### 0. 개발환경
- AWS EC2 t2.micro  
- Amazon Linux 2

### 1. 접속
~~~shell
ssh -i test-kafka-server-key.pem ec2-user@3.27.133.168
~~~

### 2. java 설치
~~~shell
$ sudo yum install -y java-1.8.0-openjdk-devel.x86_64
~~~

### 3. kafka 다운로드
https://kafka.apache.org/downloads  
3.6.1 버전의 Scala 2.13  - kafka_2.13-3.6.1.tgz (asc, sha512) 설치  
~~~shell
$ wget https://downloads.apache.org/kafka/3.6.1/kafka_2.12-3.6.1.tgz
~~~
압축해제
~~~shell
$ tar xvf kafka_2.12-3.6.1.tgz
~~~

### 4. 카프카 힙 메모리 설정
세션내 유지
~~~shell
$ export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
~~~
bash쉘 실행 시 마다 유지
~~~shell
$vi ~/.bashrc
~~~
열린 파일에 `export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"` 추가  
확인  
~~~shell
$ echo $KAFKA_HEAP_OPTS
~~~

### 5. 카프카 브로커 실행 시 메모리 설정
~~~shell
$ cat bin/kafka-server-start.sh
~~~
***kafka-server-start.sh***
- 위에 KAFKA_HEAP_OPTS를 환경변수로 설정하지 않으면, 해당 파일에 있는 KAFKA_HEAP_OPTS 를 보고 메모리가 지정된다.  
이 파일을 수정해서 힙 메모리 사이즈를 지정할 수도 있다.  
- `-daemon` 옵션은 포어그라운드가 아닌 백그라운드로 실행  
~~~shell
if [ $# -lt 1 ];
then
        echo "USAGE: $0 [-daemon] server.properties [--override property=value]*"
        exit 1
fi
base_dir=$(dirname $0)

if [ "x$KAFKA_LOG4J_OPTS" = "x" ]; then
    export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$base_dir/../config/log4j.properties"
fi

if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"
fi

EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc'}

COMMAND=$1
case $COMMAND in
  -daemon)
    EXTRA_ARGS="-daemon "$EXTRA_ARGS
    shift
    ;;
  *)
    ;;
esac

exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"
~~~

### 6. 카프카 브로커 실행 옵션 설정
~~~shell
$ vi config/server.properties
~~~
***config/server.properties***
~~~shell
# 1. 실행하는 카프카 브로커의 번호
# 클러스터 구축할 때 브로커들을 구분하기 위해 단 하나뿐인 번호로 설정해야 함
# 동일한 id를 가질 경우 비정상적인 동작 발생할 수 있음
broker.id=0

# 2. 카프카 브로커가 통신을 위해 열어둘 인터페이스 IP,port,프로토콜 설정
# 따로 설정하지 않으면 모든 IP와 port에서 접속
#listeners=PLAINTEXT://:9092

# 3. 카프카 클라이언트 또는 카프카 커맨드 라인 툴에서 접속할 때 사용하는 정보
# 현재 접속중인 EC2 IP로 변경
#advertised.listeners=PLAINTEXT://your.host.name:9092

# 4. SASL_SSL, SASL_PLAIN 보안 설정 시 프로토콜 매핑을 위한 설정
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# 5. 네트워크를 통한 처리를 할 때 사용할 네트워크 스레드 개수 설정
num.network.threads=3

# 6. 카프카 브로커 내부에서 사용할 스레드 개수 지정
num.io.threads=8

# 7. 통신을 통해 가져온 데이터를 파일로 저자할 디렉토리 위치
# 카프카 실행전 디렉토리 생성여부 확인, 디렉토리 없으면 오류 발생
log.dirs=/tmp/kafka-logs

# 8. 파티션 개수를 명시하지 않고 토픽을 생할 때 기본 설정되는 파티션 개수
# 파티션 개수가 많아지면 병렬처리 데이터양이 늘어남
num.partitions=1

# 9. 카프카 브로커가 저장한 파일이 삭제되기까지 걸리는 시간 설정
# 가장 작은 단위를 기준으로 하므로 log.retention.hours보다는 log.retention.ms 값을 설정하여 운영하는 것을 추천
# log.retention.ms 값을 -1로 설정하면 영구 보존
log.retention.hours=168

# 10. 카프카 브로커가 저장할 파일의 최대 크기 지정
# 최대 크기에 도달하면 신규 파일 생성
#log.segment.bytes=1073741824

# 11. 카프카 브로커가 저정한 파일을 삭제하기 위해 체크하는 간격 지정
log.retention.check.interval.ms=300000

# 12. 카프카 브로커와 연동할 주키퍼의 IP, port
zookeeper.connect=localhost:2181

# 13. 주키퍼의 세션 타임아웃 시간 지정
zookeeper.connection.timeout.ms=18000
~~~

### 7. 주키퍼 실행
**주키퍼** - 분산코디네이션 서비스를 제공, 카프카의 클러스터 설정 리더 정보, 컨트롤러 정보를 담고 있어 카프카를 실행하는 데에 필요한 필수 애플리케이션  

안정적 운영을 위해서 3대 이상의 서버로 구성하여 사용하지만  
동일한 서버에 카프카와 동시에 1대만 실행시켜 사용하는 것을 `Quick-and-dirty single-node`라고 부른다.  
이것은 테스트 목적으로만 사용해야 함  

**주키퍼 포어그라운드 실행**  
~~~shell
$ bin/zookeeper-server-start.sh config/zookeeper.properties
~~~
**주키퍼 백그라운드 실행**
~~~shell
$ bin/zookeeper-server-start.sh --daemon config/zookeeper.properties
~~~
**확인**
~~~shell
$ jps vm
~~~

### 8. 카프카 브로커 실행 및 로그 확인
**카프카 브로커 실행**  
~~~shell
$ bin/kafka-server-start.sh --daemon config/zookeeper.properties
~~~
**로그 확인**
~~~shell
$ tail -f logs/server.log
~~~

